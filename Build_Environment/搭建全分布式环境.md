Hadoop完全分布式环境的搭建
-------------------------------------------

###一、 大体步奏
1、 设置各个节点的名字，比如master或者slave1 2 3等
2、 每个节点的登陆账号必须是同一个，不然无法免密码ssh登陆其他节点
3、 设置各个名字与其IP地址对应
4、 设置SSH免密码登陆
5、 安装jdk hadoop发行版
6、 配置每个节点上的hadoop设置文件，包括hadoop_env.sh core-site.xml 等几个文件，写好slaves文件并将所有配置文件拷贝到各个节点上
7、 格式化以后运行start-all.sh

###二、 参考文档
+ [SSH免密码登陆详细资料](http://jingyan.baidu.com/article/2fb0ba4043124a00f2ec5f0f.html)

+ [Java环境变量设置](http://jingyan.baidu.com/article/e2284b2b61a2efe2e6118d39.html)

+ [hadoop2.5.2集群环境搭建](http://jingyan.baidu.com/article/cd4c2979196e1d756e6e6093.html)

###三、 具体过程
+ 1、 设置节点名称，需要修改/etc/hostname文件，改成需要的名字。或者是在安装系统的时候就设置好计算机的名称和用户名，要使用同一个用户名称专门用于集群。
自身的配置情况如下图：
/etc/hostname:
![hostname](https://github.com/HenryWan19/Hadoop_learning/blob/master/jpg/master_hostname.png)
/etc/hosts:
![hosts](https://github.com/HenryWan19/Hadoop_learning/blob/master/jpg/master_hosts.png)

+ 2、 设置ssh免密码登陆关键在那条命令，参考文献中已经列出了(ssh-keygen –t rsa –P ‘’)，然后使用scp拷贝用户的公钥并使用cat file1 file2 >> file完成合并。
需要注意还要修改/etc/ssh/*config文件，如参考文档所示。有时还需要使用ssh-add命令。

+ 3、jdk和hadoop发行版的安装和路径设置

+ 4、依次设置master上的几个配置文件
+ core-site.xml:
   ---
		<configuration>
		<!-- Namenode's RPC server address and port -->
			<property>
				<name>fs.defaultFS</name>
				<value>hdfs://master:9000</value>
			</property>
		</configuration>
	 
+ yarn-site.xml:
   ![yarn-site.xml](https://github.com/HenryWan19/Hadoop_learning/blob/master/jpg/xml_and_yarn.png)

###四、 出错与处理
+ 1、 SSH公钥明明都互相拷贝了，但是还是没法免密码登陆对方，提示输入密码：
我的原因是master和slave1使用了不同名字的账户登陆，所以打印出authorized_keys 的时候要提示输入密码。所以要建立同一个账户登陆各个不同的节点。
+ 2、SSH免密码登陆失败提示说找不到master用户名@slave1这样的主机密码：
master和slave上的用户名不同，导致无法设置ssh免密码登陆，这很麻烦，导致机器重新安装了
+ 3、加入了新的主机无法识别，需要根据提示修改known_hosts密码文件，可以根据出现的提示使用命令如下：
ssh-keygen -f "/home/hadoop_admin/.ssh/known_hosts -R slave1"
来重新写入slave1的新的key，因为slave1的用户和密码都变化了，但唯一不变的是机器名，而原来的known_hosts文件里面记录了slave1原来的用户名和密钥信息，发生了冲突，所以要先使用提示的命令把原有信息删除之后再重新添加。
